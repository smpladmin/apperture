version: '3.8'
services:
  airflow-scheduler:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/airflow:latest
    command:
     - scheduler
    user: '50000:0'
    environment:
      AIRFLOW__CELERY__BROKER_URL: redis://:ecc2191feb78c9c5be63458428b30812@redis:6379/0
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    networks:
     - net
    secrets:
     -
      source: airflow1.env
      target: /opt/airflow/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: airflow-scheduler
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      placement:
        constraints:
         - node.role != manager
      resources:
        reservations:
          cpus: '0.25'
          memory: 256M
        limits:
          cpus: '0.5'
          memory: 512M
  airflow-triggerer:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/airflow:latest
    command:
     - triggerer
    user: '50000:0'
    environment:
      AIRFLOW__CELERY__BROKER_URL: redis://:ecc2191feb78c9c5be63458428b30812@redis:6379/0
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    networks:
     - net
    secrets:
     -
      source: airflow1.env
      target: /opt/airflow/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: airflow-triggerer
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      placement:
        constraints:
         - node.role != manager
      resources:
        reservations:
          cpus: '0.25'
          memory: 256M
        limits:
          cpus: '0.5'
          memory: 512M
  airflow-webserver:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/airflow:latest
    command:
     - webserver
    user: '50000:0'
    environment:
      AIRFLOW__CELERY__BROKER_URL: redis://:ecc2191feb78c9c5be63458428b30812@redis:6379/0
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    ports:
     - 8080:8080
    networks:
     - net
     - traefik-public
    secrets:
     -
      source: airflow1.env
      target: /opt/airflow/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: airflow-webserver
    deploy:
      labels:
        traefik.http.routers.airflow-webserver-http.middlewares: https-redirect
        traefik.http.routers.airflow-webserver-http.entrypoints: http
        traefik.http.routers.airflow-webserver-https.tls: 'true'
        swarmpit.service.deployment.autoredeploy: 'true'
        traefik.http.routers.airflow-webserver-https.rule: Host(`airflow.staging.apperture.io`)
        traefik.http.routers.airflow-webserver-http.rule: Host(`airflow.staging.apperture.io`)
        traefik.constraint-label: traefik-public
        traefik.http.routers.airflow-webserver-https.entrypoints: https
        traefik.http.services.airflow-webserver.loadbalancer.server.port: '8080'
        traefik.docker.network: traefik-public
        traefik.enable: 'true'
        traefik.http.routers.airflow-webserver-https.tls.certresolver: le
      placement:
        constraints:
         - node.role != manager
      resources:
        reservations:
          cpus: '0.6'
          memory: 512M
        limits:
          cpus: '0.9'
          memory: 1024M
  airflow-worker:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/airflow:latest
    command:
     - celery
     - worker
    user: '50000:0'
    environment:
      AIRFLOW__CELERY__BROKER_URL: redis://:ecc2191feb78c9c5be63458428b30812@redis:6379/0
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      DUMB_INIT_SETSID: '0'
    networks:
     - net
    secrets:
     -
      source: airflow1.env
      target: /opt/airflow/.env
    logging:
      driver: json-file
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      placement:
        constraints:
         - node.role != manager
         - node.hostname != worker2
  alertmanager:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/alertmanager:latest
    networks:
     - net
     - swarmpit_net
    secrets:
     -
      source: alertmanager.env
      target: /code/.env
    logging:
      driver: json-file
    deploy:
      replicas: 0
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      resources:
        reservations:
          cpus: '0.3'
          memory: 124M
        limits:
          cpus: '0.5'
          memory: 256M
  backend:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/backend:latest
    networks:
     - net
     - traefik-public
    secrets:
     -
      source: backend.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: backend
    deploy:
      labels:
        traefik.http.routers.backend-https.service: backend
        traefik.http.routers.backend-docs.rule: Host(`apiv1.staging.apperture.io`)
          && PathPrefix(`/docs`, `/openapi.json`, `/redoc`)
        traefik.http.routers.backend-http.service: backend
        traefik.http.routers.backend-docs.tls: 'true'
        traefik.http.routers.backend-http.rule: Host(`apiv1.staging.apperture.io`)
        traefik.http.middlewares.docs-auth.basicauth.users: apperture_admin:$$apr1$$Ywq8BlBR$$ZsGmf2ZQji8GVD13SqmgS.
        traefik.http.routers.backend-https.tls.certresolver: le
        swarmpit.service.deployment.autoredeploy: 'true'
        traefik.http.routers.backend-http.entrypoints: http
        traefik.http.routers.backend-https.entrypoints: https
        traefik.constraint-label: traefik-public
        traefik.http.routers.backend-docs.entrypoints: https
        traefik.http.routers.backend-docs.tls.certresolver: le
        traefik.http.routers.backend-docs.service: backend-docs
        traefik.http.services.backend.loadbalancer.server.port: '8001'
        traefik.http.services.backend-docs.loadbalancer.server.port: '8001'
        traefik.http.routers.backend-https.tls: 'true'
        traefik.docker.network: traefik-public
        traefik.enable: 'true'
        traefik.http.routers.backend-https.rule: Host(`apiv1.staging.apperture.io`)
        traefik.http.routers.backend-http.middlewares: https-redirect
        traefik.http.routers.backend-docs.middlewares: docs-auth
      update_config:
        delay: 5s
        order: start-first
      placement:
        constraints:
         - node.role != manager
      resources:
        reservations:
          cpus: '0.5'
          memory: 512M
        limits:
          cpus: '1.0'
          memory: 2048M
  cdc_consumer:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/cdc_consumer:latest
    networks:
     - net
    secrets:
     -
      source: cdc_consumer.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-events-log-group
        awslogs-region: ap-south-1
        awslogs-stream: cdc_consumer
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    ports:
     - 8123:8123
     - 9000:9000
    volumes:
     - /ch/data:/var/lib/clickhouse/
     - /ch/logs:/var/log/clickhouse-server/
     - /ch/config.d:/etc/clickhouse-server/config.d/
     - /ch/backups:/backups
    networks:
     - net
     - traefik-public
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker3ch
  connect:
    image: debezium/connect:2.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      CONFIG_STORAGE_TOPIC: my_connect_configs
      GROUP_ID: '1'
      OFFSET_STORAGE_TOPIC: my_connect_offsets
      STATUS_STORAGE_TOPIC: my_connect_statuses
    ports:
     - 8083:8083
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      placement:
        constraints:
         - node.hostname == worker3ch
  data_processor:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/data_processor:latest
    networks:
     - net
    secrets:
     -
      source: data_processor1.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-events-log-group
        awslogs-region: ap-south-1
        awslogs-stream: dataprocessor
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      placement:
        constraints:
         - node.hostname == worker2
      resources:
        reservations:
          memory: 1000M
        limits:
          memory: 7800M
  events_consumer:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/events_consumer:latest
    networks:
     - net
    secrets:
     -
      source: events_consumer2.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-events-log-group
        awslogs-region: ap-south-1
        awslogs-stream: events_consumer
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      resources:
        reservations:
          cpus: '0.5'
          memory: 512M
        limits:
          cpus: '1.0'
          memory: 2048M
  events_producer:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/events_producer:latest
    networks:
     - net
     - traefik-public
    secrets:
     -
      source: events_producer.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-events-log-group
        awslogs-region: ap-south-1
        awslogs-stream: events_producer
    deploy:
      labels:
        traefik.http.routers.events_producer-https.tls.certresolver: le
        traefik.http.services.events_producer.loadbalancer.server.port: '8002'
        traefik.http.routers.events_producer-https.service: events_producer
        traefik.http.routers.events_producer-http.entrypoints: http
        swarmpit.service.deployment.autoredeploy: 'true'
        traefik.http.routers.events_producer-http.service: events_producer
        traefik.http.routers.events_producer-http.middlewares: https-redirect
        traefik.constraint-label: traefik-public
        traefik.http.routers.events_producer-https.entrypoints: https
        traefik.http.routers.events_producer-https.tls: 'true'
        traefik.docker.network: traefik-public
        traefik.enable: 'true'
        traefik.http.routers.events_producer-http.rule: Host(`api.staging.apperture.io`)
        traefik.http.routers.events_producer-https.rule: Host(`api.staging.apperture.io`)
      resources:
        reservations:
          cpus: '0.5'
          memory: 512M
        limits:
          cpus: '1.0'
          memory: 2048M
  frontend:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/frontend:latest
    networks:
     - net
     - traefik-public
    secrets:
     -
      source: frontend1.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: frontend
    deploy:
      labels:
        traefik.http.routers.frontend-https.rule: Host(`app.staging.apperture.io`)
        traefik.http.routers.frontend-https.entrypoints: https
        traefik.http.routers.frontend-https.tls.certresolver: le
        traefik.http.routers.frontend-http.middlewares: https-redirect
        swarmpit.service.deployment.autoredeploy: 'true'
        traefik.constraint-label: traefik-public
        traefik.http.routers.frontend-http.rule: Host(`app.staging.apperture.io`)
        traefik.http.routers.frontend-https.tls: 'true'
        traefik.http.services.frontend.loadbalancer.server.port: '3000'
        traefik.docker.network: traefik-public
        traefik.enable: 'true'
        traefik.http.routers.frontend-http.entrypoints: http
      placement:
        constraints:
         - node.hostname == worker1
      resources:
        reservations:
          cpus: '0.25'
          memory: 256M
        limits:
          cpus: '0.5'
          memory: 512M
  kafka:
    image: bitnami/kafka:latest
    environment:
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_BROKER_ID: '1'
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_NODE_ID: '1'
      KAFKA_CFG_PROCESS_ROLES: broker,controller
      KAFKA_ENABLE_KRAFT: 'yes'
      KAFKA_KRAFT_CLUSTER_ID: OTMwNzFhYTY1ODNiNGE5OT
    ports:
     - 9092:9092
    volumes:
     - kafka_data:/bitnami/kafka
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker1
  kafka2:
    image: bitnami/kafka:latest
    environment:
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_BROKER_ID: '2'
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_NODE_ID: '2'
      KAFKA_CFG_PROCESS_ROLES: broker
      KAFKA_ENABLE_KRAFT: 'yes'
      KAFKA_KRAFT_CLUSTER_ID: OTMwNzFhYTY1ODNiNGE5OT
    ports:
     - 9093:9092
    volumes:
     - kafka_data2:/bitnami/kafka
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker1
  kafka3:
    image: bitnami/kafka:latest
    environment:
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_BROKER_ID: '3'
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_NODE_ID: '3'
      KAFKA_CFG_PROCESS_ROLES: broker
      KAFKA_ENABLE_KRAFT: 'yes'
      KAFKA_KRAFT_CLUSTER_ID: OTMwNzFhYTY1ODNiNGE5OT
    ports:
     - 9094:9092
    volumes:
     - kafka_data3:/bitnami/kafka
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker2
  metabase:
    image: bjeanes/metabase-clickhouse:latest
    networks:
     - net
     - traefik-public
    logging:
      driver: json-file
    deploy:
      labels:
        traefik.http.routers.metabase-https.tls.certresolver: le
        traefik.http.routers.metabase-https.tls: 'true'
        traefik.http.routers.metabase-https.entrypoints: https
        traefik.http.routers.metabase-https.service: metabase
        traefik.http.routers.metabase-http.rule: Host(`metabase.staging.apperture.io`)
        traefik.http.routers.metabase-http.entrypoints: http
        traefik.http.routers.metabase-http.service: metabase
        traefik.http.routers.metabase.middlewares: metabase-auth
        traefik.http.routers.metabase-http.middlewares: https-redirect
        traefik.constraint-label: traefik-public
        traefik.http.middlewares.metabase-auth.basicauth.users: apperture_admin:$$apr1$$Ywq8BlBR$$ZsGmf2ZQji8GVD13SqmgS.
        traefik.http.routers.metabase-https.rule: Host(`metabase.staging.apperture.io`)
        traefik.docker.network: traefik-public
        traefik.enable: 'true'
        traefik.http.services.metabase.loadbalancer.server.port: '3000'
      resources:
        reservations:
          cpus: '0.5'
          memory: 512M
        limits:
          cpus: '1.5'
          memory: 2048M
  postgres:
    image: postgres:latest
    environment:
      POSTGRES_DB: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_USER: airflow
    ports:
     - 5432:5432
    volumes:
     - postgres_data:/var/lib/postgresql/data
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker2
      resources:
        reservations:
          cpus: '0.25'
          memory: 128M
        limits:
          cpus: '0.5'
          memory: 256M
  redis:
    image: bitnami/redis:latest
    environment:
      REDIS_PASSWORD: ecc2191feb78c9c5be63458428b30812
    ports:
     - 6379:6379
    volumes:
     - apperture_redisdata:/bitnami/redis/data
    networks:
     - net
    logging:
      driver: json-file
    deploy:
      placement:
        constraints:
         - node.hostname == worker1
      resources:
        reservations:
          cpus: '0.25'
          memory: 128M
        limits:
          cpus: '0.5'
          memory: 256M
  scheduler:
    image: 212095042672.dkr.ecr.ap-south-1.amazonaws.com/scheduler:latest
    networks:
     - net
    secrets:
     -
      source: scheduler.env
      target: /code/.env
    logging:
      driver: awslogs
      options:
        awslogs-group: apperture-staging-log-group
        awslogs-region: ap-south-1
        awslogs-stream: scheduler
    deploy:
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'
      resources:
        reservations:
          cpus: '0.2'
          memory: 124M
        limits:
          cpus: '0.4'
          memory: 256M
networks:
  net:
    driver: overlay
  swarmpit_net:
    external: true
  traefik-public:
    external: true
volumes:
  airflow_data:
    external: true
  apperture_redisdata:
    external: true
  kafka_data:
    external: true
  kafka_data2:
    external: true
  kafka_data3:
    external: true
  postgres_data:
    external: true
secrets:
  airflow1.env:
    external: true
  alertmanager.env:
    external: true
  backend.env:
    external: true
  cdc_consumer.env:
    external: true
  data_processor1.env:
    external: true
  events_consumer2.env:
    external: true
  events_producer.env:
    external: true
  frontend1.env:
    external: true
  scheduler.env:
    external: true
